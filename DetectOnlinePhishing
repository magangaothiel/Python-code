import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

# Sample phishing and legitimate URLs
phishing_urls = [
    "http://secureupdate.apple.com.validate-account.net/",
    "http://login.microsoftonline.com.support.verify.account.info/",
    # ... add more phishing URLs
]

legitimate_urls = [
    "https://www.google.com/",
    "https://www.facebook.com/",
    # ... add more legitimate URLs
]

# Create a dataset
urls = phishing_urls + legitimate_urls
labels = ["phishing"] * len(phishing_urls) + ["legitimate"] * len(legitimate_urls)

# Preprocessing function to extract features from URLs
def preprocess_url(url):
    # Extract hostname from URL
    hostname = re.findall(r"://([^/]+)", url)[0]
    return hostname

# Apply preprocessing
processed_urls = [preprocess_url(url) for url in urls]

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(processed_urls, labels, test_size=0.2, random_state=42)

# Convert URLs to a matrix of token counts
vectorizer = CountVectorizer()
X_train_counts = vectorizer.fit_transform(X_train)
X_test_counts = vectorizer.transform(X_test)

# Train a Naive Bayes classifier
classifier = MultinomialNB()
classifier.fit(X_train_counts, y_train)

# Predict using the trained model
y_pred = classifier.predict(X_test_counts)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
